<!DOCTYPE html>
<html lang="en">
    <head>
	    <script async src="https://www.googletagmanager.com/gtag/js?id=G-M3LKR3FZKM"></script>
		<script>
		  window.dataLayer = window.dataLayer || [];
		  function gtag(){dataLayer.push(arguments);}
		  gtag('js', new Date());
		
		  gtag('config', 'G-M3LKR3FZKM');
		</script>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
        <meta name="description" content="" />
        <meta name="author" content="" />
        <title>Sabid Bin Habib</title>
        <link rel="icon" type="image/x-icon" href="assets/img/favicon.ico?" />
        <!-- Font Awesome icons (free version)-->
        <script src="https://use.fontawesome.com/releases/v6.1.0/js/all.js" crossorigin="anonymous"></script>
        <!-- Google fonts-->
        <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:500,700" rel="stylesheet" type="text/css" />
        <link href="https://fonts.googleapis.com/css?family=Muli:400,400i,800,800i" rel="stylesheet" type="text/css" />
        <!-- Core theme CSS (includes Bootstrap)-->
        <link href="css/styles.css" rel="stylesheet" />
    </head>
    <body id="page-top">
        <!-- Navigation-->
        <nav class="navbar navbar-expand-lg navbar-dark bg-primary fixed-top" id="sideNav">
            <a class="navbar-brand js-scroll-trigger" href="#page-top">
                <span class="d-block d-lg-none">Sabid Bin Habib Pias</span>
                <span class="d-none d-lg-block"><img class="img-fluid img-profile rounded-circle mx-auto mb-4" src="assets/img/profile.jpg" alt="..." /></span>
            </a>
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button>
            <div class="collapse navbar-collapse" id="navbarResponsive">
                <ul class="navbar-nav">
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#about">About</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#news">News</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#expertise">Expertise</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#research">Research</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#industry">Industry Experience</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#publication">Publications</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#services">Services</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#resume">Curriculum Vitae</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#contact">Contact</a></li>
                </ul>
            </div>
        </nav>
        <!-- Page Content-->
        <div class="container-fluid p-0">
            <!-- About-->
            <section class="resume-section" id="about">
                <div class="resume-section-content">
                    <h1 class="mb-2">
                        Sabid Bin Habib Pias
                    </h1>
                    
                    <div class="subheading mb-5">
                        <! Address of phone number may go here>
                        Responsible AI |  Human-Centered AI  |  Usable Security and Privacy  
                    </div> 
                    I am a Ph.D. candidate in the Department of Computer Science at <a href="https://luddy.indiana.edu/"> Luddy School of Informatics, Computing, and Engineering</a>, Indiana University Bloomington. Additionally, I serve as a Research Assistant, advised by Professor Apu Kapadia. I'm conducting doctoral research in the area of conversational assitants and decision-making. 
                    
                    My doctoral research explores how we can use linguistic and vocal interventions to help users make better decisions within those interactions. My expertise includes <strong> developing conversational AI prototypes, experimental study design, statistical and qualitative analysis, applied machine learning and LLM fine-tuning </strong>. I have also developed an user friendly <strong>eXplainable AI (XAI)</strong> interface during my internship at <a href="https://inl.gov/">Idaho National Laboratory</a> in summer 2023. Currently, I am leading multiple projects utilizing the nuances of LLM-powered conversational agents to improve teenagers' and social media users' decision-making. Moreover, I have a profound interest in utilizing LLM fine-tuning and evaluation for trustworthy AI systems design to improve the interaction outcome for users and prevent unwanted manipulation. 
                    <br/>
                    <br/>
                    
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h4 class="mb-2">Research Approach</h3>
			            		<strong>Understand:</strong>
			           				 I begin by reviewing relevant literature, engaging in conversations with field experts, and conducting small-scale formative studies. This helps me get a clear picture of user needs, domain practices, and the significance of the problem. <br/>
			           			<strong>Prototype and Study Design:</strong>
			           				 I design user-centered AI experiences by prototyping interfaces and interaction patterns focused on addressing the specific problem. Lately, I have been placing greater emphasis on developing high-fidelity prototypes to more accurately assess how users engage with AI features. I carefully develop clear research questions and strong study protocols to ensure validity, reduce confounding factors, and support accessibility and inclusivity for the target audience.<br/>
			           			<strong>Evaluate:</strong>
			           				 I evaluate the proposed designs with mixed method studies including lab experiments and online studies. My analysis approaches consist of quantitative measures such as descriptive and inferential analyses and qualitative techniques like thematic analysis. This comprehensive approach helps me understand both how well the proposed design works and identify improvements to better serve a diverse population.<br/>
			           			<strong>Storytelling:</strong>
			           				 I believe that research is only impactful when it has a clean story. I transform my research findings into clear, engaging stories for an interdisciplinary audience. My aim is to highlight the human impact and ethical considerations, making sure my work supports responsible and useful AI.<br/>
			            </div>
                    </div>
                    
                    
                                        <p><span style="color: blue;">I am actively seeking full-time opportunities as a Research Scientist or Postdoctoral Researcher. </span> Please feel free to reach out at sabidbinhabib &lt;at&gt; gmail &lt;dot&gt; com if your team is hiring. </p>
<br/>

                    
                    <div class="social-icons">
	                    <a class="social-icon" href="mailto:sabidbinhabib@gmail.com"><i class="fa-sharp fa-solid fa-envelope"></i></a>
                        <a class="social-icon" href="https://www.linkedin.com/in/sabidbinhabib/"><i class="fa-brands fa-linkedin"></i></a>
                        <a class="social-icon" href="https://github.com/sabid-habib"><i class="fa-brands fa-github"></i></a>
                        <a class="social-icon" href="https://scholar.google.com/citations?user=rpNGXCgAAAAJ&hl=en"><i class="fa-solid fa-graduation-cap"></i></a>
                        <a class="social-icon" href="https://twitter.com/SabidHabib"><i class="fab fa-twitter"></i></a>
                        <a class="social-icon" href="https://hci.social/@sabid"><i class="fa-brands fa-mastodon"></i></a>
                    </div>
                </div>
            </section>
            <hr class="m-0" />
            

            
            
            
            <!-- News-->
             <section class="resume-section" id="news">
                <div class="resume-section-content">
                    <h2 class="mb-5">News and Updates</h2>
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <ul class="fa-ul mb-1">
								<li>
									<b>May 2025:</b> Served as an Associate Chair (AC) at ACM CSCW 2025 Posters 
								</li>
								<li><span class="fa-li"><i class="fa fa-book"></i> </span>
									<b>April 2025:</b> <a href="https://privacy.luddy.indiana.edu/publications/FAccT_2025_preprint.pdf">Full-track Paper</a> accepted in ACM Conference on Fairness, Accountability, and Transparency (FAccT) 2025
								</li>
								<li><span class="fa-li"><i class="fa fa-book"></i> </span>
									<b>April 2025:</b> Workshop paper accepted in ACM CHI 2025 Workshop on Sociotechnical AI Governance Opportunities and Challenges for HCI 
								</li>
								<hr>
								<li><span class="fa-li"><i class="fa fa-microphone"></i> </span>
									<b>November 2024:</b> Chaired the "Conversations with Machines" paper session at ACM CSCW 2024.
								</li>
								<li>
									<b>November 2024:</b> Served as a student volunteer at ACM CSCW 2024.
								</li>
								<li><span class="fa-li"><i class="fas fa-award"></i> </span>
									<b>November 2024:</b> Received special recognitions for outstanding reviews of full track papers at ACM CHI 2025
								</li>
								<li><span class="fa-li"><i class="fa fa-trophy"></i> </span>
									<b>July 2024:</b> Received the best paper award for the paper <a href="https://dl.acm.org/doi/abs/10.1145/3640794.3665545">"The Impact of Perceived Tone, Age, and Gender on Voice Assistant Persuasiveness"</a>
								</li>
								<li><span class="fa-li"><i class="fa fa-book"></i> </span>
									<b>July 2024:</b> Presented full track paper at ACM Conversational User Interfaces (CUI) 2024
								</li>
								<li>
									<b>July 2024:</b> Served as a <a href="https://eurousec24.kau.se/#organization">Program Committee (PC)</a> member at EuroUSEC 2024
								</li>
								<li>
									<b>June 2024:</b> Defended dissertation proposal defense
								</li>
								<li><span class="fa-li"><i class="fas fa-trophy"></i> </span>
									<b>May 2024:</b> Received Luddy Research Excellence award for the academic year 2023-24
								</li>
								<li>
									<b>May 2024:</b> Presented my <a href="https://arxiv.org/pdf/2404.19629">Explainable AI Research</a> at the ACM CHI 2024 Workshop on Human-Centered Explainable AI (HCXAI)
								</li>
								<li>
									<b>May 2024:</b> Paper accepted in ACM Conversational User Interfaces (CUI) 2024
								</li>
								<li>
									<b>May 2024:</b> Served as a student volunteer at ACM CHI 2024
								</li>
								<li><span class="fa-li"><i class="fa fa-book"></i> </span>
									<b>April 2024:</b> Workshop paper accepted in ACM CHI 2024 Workshop on Human-Centered Explainable AI (HCXAI)
								</li>
								<li><span class="fa-li"><i class="fa fa-book"></i> </span>
									<b>April 2024:</b> Workshop paper accepted in ACM CHI 2024 Workshop on Trust and Reliance in Evolving Human-AI Workflows (TREW) 
								</li>
								<hr>
								<li><span class="fa-li"><i class="fas fa-award"></i> </span>
									<b>November 2023:</b> Received special recognitions for outstanding reviews of full track papers at ACM CHI 2024
								</li>
								<li>
									<b>October 2023:</b> Served as a student volunteer at ACM CSCW 2023
								</li>
								<li><span class="fa-li"><i class="fas fa-trophy"></i> </span>
									<b>September 2023:</b> Received Cognizant Trust and Safety Scholarship for research in trustworthy AI
								</li>
								<li>
									<b>August 2023:</b> Presented at Idaho National Laboratory intern poster session
								</li>
								<li>
									<b>June 2023:</b> Started summer internship at Idaho National Laboratory as an XAI research intern
								</li>
								<li><span class="fa-li"><i class="fas fa-award"></i> </span>
									<b>April 2023:</b> Received special recognitions for outstanding reviews of full track papers at ACM CUI 2023
								</li>
								<hr>
								<li><span class="fa-li"><i class="fa fa-book"></i> </span>
									<b>November 2022:</b> Presented full-track paper <a href="https://dl.acm.org/doi/abs/10.1145/3555538">"Decaying Photos for Enhanced Privacy"</a> at ACM CSCW 2022
								</li>
								<li>
									<b>May 2022:</b> Served as a student volunteer at ACM CHI 2022
								</li>
								<li>
									<b>April 2022:</b> Passed Ph.D. Qualifying exam
								</li>
								<li>
									<b>April 2022:</b> Paper accepted at ACM CSCW 2022
								</li>
							</ul>
                        </div>
                    </div>
                    
                </div>
            </section>
            
            <!-- Skills-->
            <section class="resume-section" id="expertise">
                <div class="resume-section-content">
                    <h2 class="mb-5">Expertise</h2>
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <ul class="fa-ul mb-1">
								<li>
									<b>Programming Language and Frameworks:</b> Python, R, Javascript, Flask, React, LIME, SHAP
								</li>
								<li>
									<b>Deep Learning Tools:</b> PyTorch, Tensorflow, LangChain, Scikit-Learn 
								</li>
								<li>
									<b>Research Method:</b> Interviews, Diary Studies, Focus Group Study, Online Survey, Mixed Methods, Card Sorting, Tree Testing, Usabilty Testing, A/B Testing
								</li>
								<li>
									<b>Machine Learning and Large Language Model:</b> Regression, CNN, RNN, Random Forest, LLM Fine-tuning, LoRA, RAG
								</li>
								<li>
									<b>Statistical Analyses:</b> Correlation, T-test, Regression, Mixed Effect Model, Pairwise Comparison, Non-parametric Tests, Factor Analyses, Clustering, Mediation Analysis
								</li>
								<li>
									<b>Other Tools:</b> Git, SQL, REST API, GPT API, Amazon Skills, Tool Calling, Microsoft Speech Studio, Qualtrics, Overleaf, Zotero
								</li>
							</ul>
                        </div>
                    </div>
                    
                </div>
            </section>
           
            <!-- Research-->
            <section class="resume-section" id="research">
                <div class="resume-section-content">
                    <hr>
                    <center><h3>Full-track Papers</h3></center>
                    <hr>
                    <h3><u>Human-centered AI</h3></u>
                    </br>
	                    
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h4 class="mb-2">Towards the Persuasiveness of Conversational Assistants' Vocal Tone</h4>
                            
                        	<a href="https://dl.acm.org/doi/abs/10.1145/3640794.3665545">ACM Conversational User Interface 2024 (CUI)</a> | <i class="fa fa-trophy"></i> <strong>Best Paper Award</strong> | <i class="fas fa-pen"></i> <strong>Lead Author</strong>
                        	<br> 
	                        <br>                        Suppose you are rushing to complete morning chores while asking your digital assistant to read your day's schedule. Would you register the important deadline when it responds in a flat, mechanical voice listing your appointments? Or would you be more attentive when the same assistant delivers your schedule in a warm, conversational tone that emphasizes priorities? This striking difference in response to identical information raises a compelling research question: how do voice assistants' tonal qualities and speaking patterns influence not just your satisfaction with the technology, but your actual decision-making processes and willingness to follow their guidance? </br>

This research explores whether voice assistants-like Alexa or Siri-can have a similar impact. Specifically, we investigated how the tone, age, and gender of a voice assistant influence whether people follow its product recommendations. Our experiment demonstrated that <b>participants preferred positive and neutral tones from the agents and recommended that tone be customized based on the task and context. We also found a preference for stereotypical inclinations toward younger female and older male voices.</b> This research provides insights into how these vocal qualities shape user decisions, which can help designers create voice technologies that are not only more effective but also more ethical. </br>

Importantly, this study was conducted before large language models (LLMs) like ChatGPT introduced advanced voice features to the public. At that time, commercial voice assistants relied on fixed, pre-designed voices, making our findings especially relevant for understanding how specific vocal qualities shape user trust and engagement. Now, as LLM-powered voice assistants enable more natural, continuous, and human-like conversations, this research provides foundational insights for designing these new systems. By identifying which voice characteristics incite persuasiveness and comfort, our work guides the creation of user-centered, ethical voice interactions. This is crucial for the next generation of human-LLM interaction in the voice modality, where the ability to adapt voice features can be utilized to enhance user experience and trust. </br></br>
		                <strong>Methods: </strong>Interactive user study, A/B Testing, Statistical analysis, Qualitative Analysis, Voice Synthesis</br>
			            <strong>Tools: </strong> Python, R, Javascript, Microsoft Speech Studio, Qualtrics</br>
			            </div>
                    
                    </div>
                    
                    
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h4 class="mb-2">Not All Errors Are Equal: How Timing and Severity of AI Errors Impact User Trust</h4>
                            
                        	<a href="https://privacy.luddy.indiana.edu/publications/FAccT_2025_preprint.pdf">ACM Conference on Fairness, Accountability, and Transparency 2025 (FAccT)</a> | <i class="fas fa-pen"></i> <strong>Second Author</strong></br>
                        	</br>                        Have you ever relied on AI to automate repetitive yet critical tasks, such as screening images to ensure they're safe for children? Imagine your trusted AI mistakenly labels an inappropriate image as safe. Would your trust remain the same, or would doubts start to creep in? </br>

Inspired by these motivations, we investigated how the timing and severity of AI errors shape user trust. We discovered that <b> a severe mistake late in an AI’s process, especially in high-stakes areas like defense or social media moderation-can quickly erode trust, even if the AI performed flawlessly before</b>. Smaller or early errors are more easily forgiven if the system proves reliable afterward. This pattern matters because trust is essential for people to accept, rely on, and benefit from AI systems. If trust is lost, users may misuse, over-rely on, or reject helpful technology. </br>

As AI becomes more common in critical decision-making, understanding and regulating these trust patterns is crucial for safety, transparency, and ethical use. Our findings provide practical guidance for building AI systems that align with human expectations, promote responsible adoption, and support regulatory oversight-ensuring trust becomes a strength, not a vulnerability, in human–AI collaboration </br></br>
		                <strong>Methods: </strong>Online User Study, Statistical analysis, Qualitative Analysis, A/B Testing</br>
			            <strong>Tools: </strong> Python, R, Javascript, Qualtrics</br>
			            </div>
                    
                    </div>
                    
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
			            <div class="flex-grow-1">
                            <h4 class="mb-2">LLM-Generated Privacy Nudges in Social Media Decision-Making</h3>
                        	<i>Under Review</i> | <strong>Lead Author</strong>
                        	</br></br>
                        Imagine scrolling through social media and finding a funny, embarrassing photo that reminds you of your friends-you want to share it, but how would you feel if you were the person in the photo? Our research explores whether large language models (LLMs) can provide timely, gentle reminders before sharing, helping users make more considerate decisions without being intrusive. We found that brief, clear prompts and personalized guidance are most effective, empowering users to share thoughtfully and protect privacy.<br/>
		                <strong>Methods: </strong> Mixed Method Study, User Study Design, Statistical Analyses, Qualitative Analyses</br>
			            <strong>Tools: </strong> OpenAI API, Python, R, Qualtrics</br>
			            </div>
                    </div>

                    
                    <hr>
                    <h3><u>Usable Security and Privacy</h3></u>
                    </br>
                    
                    
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h4 class="mb-2">Decaying Photos for Enhanced Privacy</h4>
                        	<a href="https://dl.acm.org/doi/10.1145/3555538">ACM Conference on Computer-Supported Cooperative Work and Social Computing 2024 (CSCW)
</a> | <strong>Lead Author</strong></br></br>
                        Suppose you’re at a family gathering, and everyone wants to take group photos to remember the day. Some people are happy to share every picture right away, while others worry about a messy background, a bystander caught in the shot, or their house number showing. You might wonder: Is there a way to share these memories while also respecting everyone’s privacy and keeping sensitive details safe, even after the photos are shared?</br>
                        This is the kind of challenge today’s social media users face: balancing the joy of sharing with the need to protect personal and bystander privacy. Traditional solutions like instantly covering up sensitive parts of a photo can make the image less enjoyable, while apps that delete photos after a short time (like Snapchat) do not let people preserve memories.</br>
                        We explore a new approach called "temporal redactions," where sensitive parts of a photo are gradually or later hidden after sharing, letting people enjoy the full image at first but protecting privacy over time. By studying how people feel about these techniques across different audiences (like family, friends, or the public), we found that <b>many users prefer having more flexible and context-aware privacy options</b>,especially for photos with personal details or bystanders.</br>
                        This research provides insights to design better privacy tools for social platforms. It shows that privacy isn’t one-size-fits-all: people want control over what’s visible, for how long, and to whom. By understanding these preferences, platforms can offer smarter, more user-friendly ways to share memories without sacrificing privacy-empowering users to share confidently in a digital world.</br></br>		                
                        <strong>Methods: </strong>Quantitative Study, User interface design </br>
			            <strong>Tools: </strong> R, Python, Javascript, Qualtrics
			            </div>
                    </div>
                    
                                        
                    <hr>
                    <center><h3>Workshop Papers and Extended Abstracts</h3></center>
                    <hr>
                    
                   
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h4 class="mb-2">Personality and Explainability: How Detailed Explanations Impact Agreement with XAI</h3>
                        	<a href="https://arxiv.org/abs/2404.19629">ACM CHI 2024 Workshop on Human-Centered Explainable AI (HCXAI)</a> | <strong>Lead Author</strong></br></br>
                        Suppose you’re attending a cooking class, and the chef is teaching everyone how to prepare a complex dish. Some students want to know every detail-why each ingredient is added, the science behind each step, and how to fix mistakes along the way. Others just want clear, simple instructions so they don’t get overwhelmed. Why would some people crave detailed explanations while others prefer to keep things straightforward? </br>
                        We investigated people's preference and agreement with AI explanations motivated by this phenomenon. <b>We found that people who are more anxious or less comfortable with technology actually AI interfaces more when it gives short, simple answers instead of long explanations</b>. Meanwhile, people who are more organized or comfortable with tech might appreciate more detail. The key takeaway is that not everyone wants or benefits from the same type of explanation-so for AI systems to be truly helpful and trustworthy, they should adjust how much they explain based on each person’s needs and comfort level. </br>
                        This research provides Explainable AI design insights by showing that one-size-fits-all explanations may not serve everyone equally well, and that considering user personality and technological comfort is crucial for designing trustworthy, accessible, and user-friendly AI systems </br></br>
		                <strong>Methods: </strong>Quantitative analysis, Interactive user study design, A/B Testing</br>
			            <strong>Tools: </strong> Python, R, Qualtrics</br>
			            </div>
                    </div>

                    
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h4 class="mb-2">Effect of Mistake Timing and Severity in the Trust Dynamics in Human-AI Collaboration</h3>
                        	<a href="https://chi-trew.github.io/papers/2024/CHI_TREW_2024_Paper_7.pdf">ACM CHI 2024 Workshop in Trust and Reliance in Evolving Human-AI Workflows (TREW)</a> | <strong>Second Author</strong></br></br>
                        	Think of a resturent where a chef is preparing a multi-course meal. If they burn the appetizer but serves the perfect dishe for the rest of the meal, what would you thik of the chef? If they make a minor mistake with the dessert after serving flawless courses, would you still trust them to cook for you again?</br>
                        	This abstract proposes an experiment to evaluate the similar impacts human-AI interactions may experience: how the timing and severity of AI errors impact trust in high-stakes systems (e.g., military, social media moderation). It also discusses ethical considerations and the potential impact of the experiment results.</br></br>
                        	
                        <strong>Methods: </strong>User-centric Study Design</br>
			            <strong>Tools: </strong> Python</br>
			            </div>
			        </div>
                    
                    
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h4 class="mb-2">Effects of Vocal Tone on the Trustworthiness of Voice Assistants</h3>
                        	<i>Under Review</i> | <strong>Lead Author</strong></br></br>
                        Imagine you’re shopping online and need advice. You can ask two salespeople: one speaks in a warm, friendly tone, while the other sounds flat or even a bit negative. Which one would you trust more with your purchase decision-and why does their tone make such a difference?</br>
                        This poster investigated the similar effect in voice assistant interactions: how the vocal tone of voice assistants (VAs) influences how attractive and trustworthy they seem during complex tasks like online shopping. The study found that VAs using positive or neutral tones were rated as more appealing and trustworthy than those with negative tones. The perceived attractiveness of the VA’s voice played a key role in building trust, while factors like the voice’s age or gender had little effect.</br>
                        This research shows that thoughtful voice design can make VAs more engaging and trustworthy for users, encouraging broader adoption for complex tasks. As voice assistants become more central to daily life, designing voices that elicit genuine trust can improve user experience and help people make better decisions with confidence.</br></br>
                        
		                <strong>Methods: </strong>Mixed method study, Quantitative Analyses</br>			            
		                <strong>Tools: </strong> Python, R, Javascript
			            </div>
                    </div>
                    

                </div>
            </section>
            <hr class="m-0" />
            
            <!-- Industry Experience-->
            <section class="resume-section" id="industry">
                <div class="resume-section-content">
                    <h2 class="mb-4">Industry Experience</h2>
                    <hr>
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h4 class="mb-2">Idaho National Laboratory</h4>
	                        <strong>Python Programmer Intern, Summer 2023 | Internship </strong>
                        </br></br>
                        Technicians at water treatment plants typically monitor numerous sensor outputs across different sections of the facility to anticipate and locate potential faults. This process can be both time-consuming and cognitively demanding. To address this challenge, I developed a <strong>machine learning application that predicts water plant faults using Random Forest, Support Vector Regression, and Neural Network</strong>, achieving an accuracy of 98%. To ensure the predictions are interpretable and actionable, I also built an <strong>explainable AI interface</strong> incorporating LIME and SHAP, enabling technicians to understand the rationale behind each prediction.</br></br>
		                <strong>Methods: </strong>Explainable AI (XAI), Machine Learning, Software Development, Data Visualization, Usability Study Design</br>
			            <strong>Tools: </strong> Python, PyTorch, LIME, SHAP, PyQT
			            </div>
                    </div>
                    
                    
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h4 class="mb-2">Field Information Solutions GmbH</h4>
	                        <strong>Android Application Developer, January 2017- May 2019 | Full Time</strong>
                        </br></br>
                        In many low-resource settings, representatives from distribution and agricultural procurement companies frequently visit local shops or rural farms to collect data on product demand and harvest volumes. These insights are critical for ensuring timely product delivery to retail outlets and efficient procurement from producers. </br>

To support this process, we developed a user-centered Android application designed for field representatives to capture nuanced data both offline and online. The application simplifies data entry, transmission, and format customization to suit diverse organizational needs. Built as a <strong>Software-as-a-Service (SaaS) solution</strong>, the platform allowed client organizations to configure survey structures and workflows according to their specific operational contexts. The application has been deployed across <strong> inaccessible and remote areas in Bangladesh, Myanmar, Uganda, Kenya, Afghanistan, and Nepal, serving over 3,000 field representatives.</strong> </br>

As part of this initiative, I led to the development of the following core modules:</br></br>
		                <strong>Survey Container (Android, Java, Realm, REST API) </strong></br>
		                Designed a dynamic survey builder that maps large question sets to mobile forms. Integrated regex-based validation logic to ensure structured and accurate user responses aligned with survey instructions.</br>
			            <strong>Product Sales Prediction (Python) </strong></br> 
			            Built a supervised regression model to forecast product sales, based on a 24-month transaction dataset from field agents to inform logistics and inventory planning.</br>
			            <strong>Remote Sales Tracker Builder (Android, NoSQL, REST API) </strong></br> 
			            Created a modular tool to help micro-entrepreneurs construct custom sales tracking applications. Implemented a time-based synchronization mechanism to maintain data integrity in low-connectivity environments.</br>
			            <strong>Inventory Updater (Android, NoSQL, REST API) </strong></br> 
			            Developed a robust inventory management interface allowing representatives to update stock levels in bulk or individually. Included support for real-world complexities such as product returns, expired items, loans, advance payments, and image-based documentation.</br>
			            
			            </div>
                    </div>
                    
                    
                    
                </div>
            </section>
            <hr class="m-0" />
            
             <!-- Publication-->
            <section class="resume-section" id="publication">
                <div class="resume-section-content">
                    <h2 class="mb-5">Publications</h2>
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <ul class="fa-ul mb-1" >
								<li><span class="fa-li"><i class="fa fa-book"></i></span>
									<p class="lead mb-1">Alicia Freel, <b>Sabid Bin Habib Pias</b>,  Selma Sabanovic, Apu Kapadia. <a href="https://privacy.luddy.indiana.edu/publications/FAccT_2025_preprint.pdf"><i>How Misclassification Severity and Timing Influence User Trust in AI Image Classification: User Perceptions of High- and Low-Stakes Contexts</i></a> In <b>ACM Conference on Fairness, Accountability, and Transparency, FAccT 2025</b></p>
								</li>
								<br>
								<li><span class="fa-li"><i class="fa fa-trophy"></i> </span>
									<p class="lead mb-1"><b>Sabid Bin Habib Pias</b>, Ran Huang, Donald Williamson, Minjeong Kim, and Apu Kapadia.<i><a href="https://dl.acm.org/doi/abs/10.1145/3640794.3665545">The Impact of Perceived Tone, Age, and Gender on Voice Assistant Persuasiveness in the Context of Product Recommendations.</a></i> In <b>ACM Conference on Conversational User Interface, CUI 2024 (Best Paper)</b></p>
								</li>
								<br>
								<li><span class="fa-li"><i class="fa fa-book"></i></span>
									<p class="lead mb-1"><b>Sabid Bin Habib Pias</b>, Alicia Freel, Timothy Trammel, Taslima Akter, Donald Williamson, and Apu Kapadia. <a href="files/hcxai-paper.pdf"><i>The Drawback of Insight: Detailed Explanations Can Reduce Agreement with XAI.</i></a> In <b>ACM CHI Workshop on Human Centered Explainable AI, CHI 2024</b></p>
								</li>
								<br>
								<li><span class="fa-li"><i class="fa fa-book"></i></span>
									<p class="lead mb-1">Alicia Freel, <b>Sabid Bin Habib Pias</b>,  Selma Sabanovic, Apu Kapadia. <i>Navigating Trust Erosion in Human-AI Collaboration: Unpacking the Impact of Severity and Timing in Misclassification.</i> In <b>ACM CHI Workshop on Trust and Reliance in Evolving Human-AI Workflows, CHI 2024</b></p>
								</li>
								<br>
								<li><span class="fa-li"><i class="fa fa-book"></i></span>
									<p class="lead mb-1"><b>Sabid Bin Habib Pias</b>, Imtiaz Ahmad, Taslima Akter, Adam J. Lee, and Apu Kapadia. <a href="https://dl.acm.org/doi/10.1145/3555538"><i>Decaying Photos for Enhanced Privacy: User Perceptions Towards Temporal Redactions and Trusted Platforms</i></a>. In <b>ACM Conference On Computer-Supported Cooperative Work (CSCW'22)</b></p>
								</li>
								 
							</ul>
                        </div>
                    </div>
                    
                </div>
            </section>
            <hr class="m-0" />
             
             <!-- Industry Experience-->
            <section class="resume-section" id="services">
                <div class="resume-section-content">
                    <h2 class="mb-4">Services</h2>
                    <hr>
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
	                        <h3 class="mb-4">Academic Services</h3>
	                        <strong>Conference Program Committee:</strong> <a href="https://cscw.acm.org/2025/index.php/posters/">ACM CSCW ' 25 Posters (Associate Chair)</a>, <a href="https://eurousec2025.cis.strath.ac.uk/#organization">EuroUSEC 2025</a>, <a href="https://eurousec24.kau.se/#organization">EuroUSEC 2024</a>
                        	</br>
                        	<strong>Peer Review:</strong> ACM CHI, ACM CSCW, ACM CUI, IEEE Transactions on Privacy, ACM UIST, HRI, ACM DIS, ACM IUI, ICWSM, IMX, EuroUSEC
                        	</br>
                        	<strong>Recognition for Outstanding Peer Review:</strong> ACM CHI, ACM CSCW, ACM CUI
                        	</br>
                        	<strong>Student Volunteer:</strong> ACM CHI (' 24, ' 22), ACM CSCW (' 24, ' 23, ' 22), ACM CUI ' 24
                        	</br>
                        	<strong>Mentoring Junior Co-chair:</strong> <a href="https://www.usenix.org/conference/soups2023/mentoring-program">SOUPS 2023</a>
                        	</br>
                        	<strong>Paper Session Moderator:</strong> CSCW 2024
                        	</br>
                        	<strong>Undergraduate Research Mentor, Indiana University:</strong> 2022-2025
                        	</br></br>
                        	
                        	<h3 class="mb-4">Organizational and Volunteer Activities</h3>
                        	Luddy Graduate Ambassador, Luddy School, Indiana University, <i>2022-25</i>
                        	</br>
                        	Graduate Representative, Luddy School Student Government, <i>2021-22</i>
                        	</br>
                        	Vice President, Bangladesh Student Association at Indiana University, <i>2021-22</i>
                        	</br>
                        	Member and Organizer of Laboratorians Student Association of BUETians (LAB), <i>2014-15</i>
                        	</br>
                        
			            </div>
                    </div>                    
                    
                    
                </div>
            </section>
            <hr class="m-0" />


            <!-- Contact-->
            <section class="resume-section" id="resume">
                <div class="resume-section-content">
                    <h2 class="mb-5">Curriculum Vitae</h2>
                    <p class="mb-0"><a href="files/sabid-cv.pdf">Click here to download my CV</a></p>
                    <p class="mb-0"><a href="files/sabid-resume.pdf">Click here to download my Resume</a></p>
                </div>
            </section>
            <!-- Contact-->
            
            <section class="resume-section p-3 p-lg-5 d-flex flex-column" id="contact">
                <div class="resume-section-content">
                    <h2 class="mb-5">Contact</h2>
                    <p class="mb-5">Email: <a href="mailto:sabhabib@iu.edu">sabhabib [at] iu [dot] edu</a> or <a href="mailto:sabidbinhabib@gmail.com">sabidbinhabib [at] gmail [dot] com</a> </p>
                </div>
              
            </section>
            <hr class="m-0" />
        </div>
        
        <!-- Bootstrap core JS-->
        <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>
        <!-- Core theme JS-->
        <script src="js/scripts.js"></script>
    </body>
    
    
    
</html>



          
